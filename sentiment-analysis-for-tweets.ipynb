{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/faryalrifaz3374/sentiment-analysis-for-tweets?scriptVersionId=264604330\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Project : Sentiment Analysis on Tweets**  \n\n## **Auther: Faryal Rifaz** \n\n##  **Objective**  \nThe objective of this project is to build a sentiment analysis tool using Python and NLTK to classify tweets as **positive, negative, or neutral**.  \n\n---","metadata":{}},{"cell_type":"markdown","source":"##  Step 1: Import Libraries  ","metadata":{}},{"cell_type":"code","source":"# Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom bs4 import BeautifulSoup\nimport re\nimport string\nfrom textblob import TextBlob\nimport nltk\nfrom nltk.corpus import stopwords\nimport emoji\nnltk.download('punkt')\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('wordnet')\nfrom keras.preprocessing import sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom keras.layers import LSTM, Dense, SimpleRNN, Embedding, Flatten, Dropout\nfrom keras.activations import softmax\nfrom sklearn.model_selection import train_test_split\n# ignore warnings   \nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 2: Import Data ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Training dataset\ntrain = pd.read_csv(\n    \"/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv\",\n    header=None,\n    names=[\"ID\", \"Topic\", \"Sentiment\", \"Text\"]\n)\n\n# Validation dataset\nvalid = pd.read_csv(\n    \"/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv\",\n    header=None,\n    names=[\"ID\", \"Topic\", \"Sentiment\", \"Text\"]\n)\n\n# Show top rows \n\ntrain.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3: Preprocessing","metadata":{}},{"cell_type":"markdown","source":"In this step, we clean the raw tweet texts to make them suitable for analysis.  \nThe preprocessing pipeline includes:\n1- Converting text to lowercase  \n2- Removing URLs, mentions, hashtags, punctuation, and special characters  \n3- Tokenization (splitting sentences into words)  \n4- Stopword removal (removing common words like \"the\", \"is\", \"at\")  \n5- Lemmatization (converting words to their base form, e.g., \"running\" â†’ \"run\")  \n\nThis ensures that the machine learning model focuses only on meaningful information.\n","metadata":{}},{"cell_type":"code","source":"import re\nimport html\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n# download resources \nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('omw-1.4')\n\n# stopwords & lemmatizer\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\n# cleaning function\ndef clean_text(text):\n    if not isinstance(text, str):\n        return \"\"\n    text = html.unescape(text)                 # decode HTML\n    text = text.lower()                        # lowercase\n    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)   # remove urls\n    text = re.sub(r'@\\w+', ' ', text)          # remove mentions\n    text = re.sub(r'#', ' ', text)             # remove hash only\n    text = re.sub(r'[^a-z0-9\\s]', ' ', text)   # keep alnum + spaces\n    tokens = nltk.word_tokenize(text)          # tokenize\n    tokens = [t for t in tokens if t not in stop_words and len(t) > 1]\n    tokens = [lemmatizer.lemmatize(t) for t in tokens]  # lemmatize\n    return \" \".join(tokens)\n\n# apply on both datasets\ntrain['clean_text'] = train['Text'].apply(clean_text)\nvalid['clean_text'] = valid['Text'].apply(clean_text)\n\n# check sample\nprint(train[['Text','clean_text']].head(10))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 4: Encode labels ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#  Label encoding, fit on combined labels to ensure consistent mapping\nle = LabelEncoder()\nle.fit(pd.concat([train['Sentiment'], valid['Sentiment']], axis=0))\ntrain['label_enc'] = le.transform(train['Sentiment'])\nvalid['label_enc'] = le.transform(valid['Sentiment'])\nprint(\"Label mapping (index -> label):\", dict(enumerate(le.classes_)))\n\n# Show class distribution\nprint(\"\\nTrain class counts:\\n\", train['Sentiment'].value_counts())\nprint(\"\\nValid class counts:\\n\", valid['Sentiment'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 5: TF-IDF","metadata":{}},{"cell_type":"code","source":"# TF-IDF vectorization\ntfv = TfidfVectorizer(max_features=10000, ngram_range=(1,2), stop_words='english')\nX_train = tfv.fit_transform(train['clean_text'])\nX_valid = tfv.transform(valid['clean_text'])\ny_train = train['label_enc']\ny_valid = valid['label_enc']\n\nprint(\"\\nTF-IDF matrix shapes, X_train, X_valid:\", X_train.shape, X_valid.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 6: Compare Multiple Models","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\n\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n    \"Naive Bayes\": MultinomialNB(),\n    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n    \"Linear SVM\": LinearSVC(random_state=42)\n}\n\nresults = {}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    acc = accuracy_score(y_valid, preds)\n    results[name] = acc\n    print(f\"{name} Accuracy: {acc:.4f}\")\n\n# Convert results to DataFrame for easy plotting\nres_df = pd.DataFrame(list(results.items()), columns=[\"Model\", \"Accuracy\"])\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 7:  Visualization","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize=(8,5))\nsns.barplot(x=\"Model\", y=\"Accuracy\", data=res_df, palette=\"viridis\")\nplt.title(\"Model Comparison on Validation Set\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(rotation=30)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 8: Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, roc_curve, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import label_binarize\n\n# Binarize labels for ROC\ny_valid_bin = label_binarize(y_valid, classes=range(len(le.classes_)))\nn_classes = y_valid_bin.shape[1]\n\nplt.figure(figsize=(12, 8))\n\nfor idx, (name, model) in enumerate(models.items(), 1):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_valid)\n    \n    # Accuracy\n    acc = accuracy_score(y_valid, y_pred)\n    print(f\"\\n{name} Accuracy: {acc:.4f}\")\n    \n    # Classification report\n    print(classification_report(y_valid, y_pred, target_names=le.classes_))\n    \n    # Confusion matrix\n    print(f\"Confusion Matrix for {name}:\")\n    disp = ConfusionMatrixDisplay.from_estimator(model, X_valid, y_valid,\n                                                 display_labels=le.classes_,\n                                                 cmap='Blues',\n                                                 xticks_rotation=30)\n    \n    # ROC curve for multiclass\n    y_score = model.predict_proba(X_valid) if hasattr(model, \"predict_proba\") else None\n    if y_score is not None:\n        plt.figure(figsize=(7,5))\n        for i in range(n_classes):\n            fpr, tpr, _ = roc_curve(y_valid_bin[:, i], y_score[:, i])\n            plt.plot(fpr, tpr, label=f\"{le.classes_[i]}\")\n        plt.plot([0,1], [0,1], 'k--')\n        plt.title(f\"{name} ROC Curve\")\n        plt.xlabel(\"False Positive Rate\")\n        plt.ylabel(\"True Positive Rate\")\n        plt.legend()\n        plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 9: Final Model ","metadata":{}},{"cell_type":"code","source":"# Random Forest chosen as final model\nprint(\"Final Model Selected: Random Forest\")\n\n# Retrain on full dataset\nX_full = tfv.fit_transform(pd.concat([train['clean_text'], valid['clean_text']], axis=0))\ny_full = pd.concat([train['label_enc'], valid['label_enc']], axis=0)\n\nfinal_model = RandomForestClassifier(n_estimators=200, random_state=42)\nfinal_model.fit(X_full, y_full)\n\n# Save final model and preprocessing objects\nimport joblib\njoblib.dump(final_model, \"final_random_forest.pkl\")\njoblib.dump(tfv, \"final_tfidf_vectorizer.pkl\")\njoblib.dump(le, \"final_label_encoder.pkl\")\n\nprint(\"\\nFinal model and preprocessing objects saved successfully\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 10: Conclusion","metadata":{}},{"cell_type":"markdown","source":"The Random Forest classifier showed high performance for tweet sentiment analysis, achieving the best accuracy among applied models. ","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}}]}